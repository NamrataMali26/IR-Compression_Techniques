{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to build Index using lemmatization: version 1: 1.1601014137268066 seconds\n",
      "Elapsed time to build Index using lemmatization : version 2: 4.350997447967529 seconds\n",
      "\n",
      "Size of the Index version 1 uncompressed (in bytes): 558283\n",
      "Size of the Index version 2 uncompressed (in bytes): 417636\n",
      "\n",
      "Size of the Index compressed using blocked compression & unary coding (in bytes): 380880\n",
      "Size of the Index compressed using blocked compression & gamma encoding (in bytes): 237252\n",
      "Size of the Index compressed using blocked compression & delta encoding (in bytes): 239253\n",
      "Size of the Index compressed using front coding & unary codes (in bytes): 21098\n",
      "Size of the Index compressed using front coding & gamma codes (in bytes): 11394\n",
      "Size of the Index compressed using front coding & delta codes (in bytes): 11467\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "import time\n",
    "import math\n",
    "import sys\n",
    "import json\n",
    "from array import array\n",
    "from _collections import defaultdict\n",
    "import operator\n",
    "import pickle\n",
    "from sys import getsizeof\n",
    "from operator import itemgetter\n",
    "from audioop import reverse\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "#Create a dictionary in the form self.entry = {'term':t,'docFreq':df,'termFreq':tf,'postingList':pl}\n",
    "class DictEntry:\n",
    "    def __init__(self,t,df,tf,pl):\n",
    "        self.term = t\n",
    "        self.docFreq = df\n",
    "        self.totTermFreq = tf\n",
    "        self.postingList = pl\n",
    "\n",
    "        \n",
    "class PostingEntry:\n",
    "    def __init__(self,did,freq,maxtf,docl):\n",
    "        self.docId = did\n",
    "        self.termFreq = freq\n",
    "        self.maxTermFreq = maxtf\n",
    "        self.docLen = docl \n",
    "    def __iter__(self):\n",
    "        return self.__dict__.iteritems()\n",
    "\n",
    "#Function to get unary code\n",
    "def getUnaryValue(leng):\n",
    "    unaryValue = \"\"\n",
    "    for i in range(0,leng):\n",
    "        unaryValue += str(1)\n",
    "    return unaryValue + str(0)\n",
    "\n",
    "#Function to get Delta code\n",
    "def getDeltaCode(num):\n",
    "    binaryRep = str(bin(num))[2:]\n",
    "    gammaCode = getGammaCode(len(binaryRep))\n",
    "    offset = binaryRep[1:]\n",
    "    deltaCode = gammaCode + offset\n",
    "    return deltaCode\n",
    "\n",
    "#Function to get Gamma code\n",
    "def getGammaCode(num):\n",
    "    binaryRep = str(bin(num))[2:]\n",
    "    offset = binaryRep[1:]\n",
    "    unaryValue = getUnaryValue(len(offset))\n",
    "    gammaCode = unaryValue + offset\n",
    "    return gammaCode#byteGamma\n",
    "\n",
    "#Function to get Maximum Term Frequency of Document code\n",
    "def getMaxTermFreqDocLen(dictf):\n",
    "    docLeng = 0\n",
    "    maxTermFreq = 0\n",
    "    for items in dictf:\n",
    "        termFreq = dictf[items]\n",
    "        docLeng += termFreq\n",
    "        if not items in stopWords:\n",
    "            if termFreq > maxTermFreq:\n",
    "                maxTermFreq = termFreq\n",
    "    return maxTermFreq,docLeng \n",
    "                \n",
    "def insertDict(docId, token, termFreq, dictionary, maxTermFreq, docLeng):\n",
    "    entry = dictionary.get(token)\n",
    "    if entry is None:\n",
    "        postingList = []\n",
    "        entry = DictEntry(token,0,0,postingList)\n",
    "        dictionary[token] = entry       \n",
    "\n",
    "    entry.docFreq +=1\n",
    "    postEntry = PostingEntry(docId,termFreq,maxTermFreq,docLeng)\n",
    "    entry.postingList.append(postEntry)\n",
    "    entry.totTermFreq+= termFreq\n",
    "\n",
    "#Tokenization of text\n",
    "def Tokenize(files):\n",
    "    textFile = open(files,\"r\")\n",
    "    lText = textFile.read().lower()\n",
    "    plainWord = re.sub('<[^>]*>','', lText)\n",
    "    text = re.sub(r'\\.(?![a-zA-Z]{3})', '', plainWord)\n",
    "    text = text.replace(\"\\'s\",\"\")\n",
    "    #text = text.replace(\"\\'[a-z]+\",' ')\n",
    "    words =re.sub('[^a-zA-Z]+', ' ', text).split()\n",
    "    # re.split(r'[-=\\.,?!:$;_()\\[\\]\\`\\'*\"/\\t\\n\\r\\d+ \\x0b\\x0c]+', text)\n",
    "    ##re.sub(r\"\\p{P}+\", \"\", text.lower()).split()#\n",
    "    textFile.close()\n",
    "    return [word.strip() for word in words if word.strip() != '']\n",
    "        \n",
    "#Lemmatiztion of text   \n",
    "def Lemmatiztion():        \n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    for docId ,dfile in enumerate(filesList,1): \n",
    "        dictWord = {}        \n",
    "        listWord = Tokenize(dfile)\n",
    "        for word in listWord:\n",
    "                tWord = lmtzr.lemmatize(word)\n",
    "                #print tWord\n",
    "                dictWord[tWord] = dictWord.get(tWord,0)+ 1\n",
    "        \n",
    "        mxtf, dolen = getMaxTermFreqDocLen(dictWord)\n",
    "        for items in dictWord:\n",
    "            termFreq = dictWord[items]\n",
    "            if not items in stopWords :    \n",
    "                insertDict(docId,items,termFreq,dictionary_uncomp_v1,mxtf,dolen)\n",
    "\n",
    "        del dictWord\n",
    "\n",
    "#Perform stemming operation on text \n",
    "def Stemming():\n",
    "    stmr = PorterStemmer()\n",
    "    for docId ,dfile in enumerate(filesList,1):\n",
    "        listWord = Tokenize(dfile)    \n",
    "        stemWord = {}        \n",
    "        for w in listWord:\n",
    "            tempStem = stmr.stem(w) \n",
    "            stemWord[tempStem]= stemWord.get(tempStem,0)+1\n",
    "        \n",
    "        mxtf, dolen = getMaxTermFreqDocLen(stemWord)\n",
    "        \n",
    "        for items in stemWord:\n",
    "            termFreq = stemWord[items]    \n",
    "            if not items in stopWords :    \n",
    "                insertDict(docId,items,termFreq,dictionary_uncomp_v2,mxtf,dolen)\n",
    "        \n",
    "        del stemWord\n",
    "\n",
    "def getDocLargestMaxTF(dictionary_uncomp):\n",
    "    maz=0\n",
    "    for term in dictionary_uncomp.keys():\n",
    "        entry = dictionary_uncomp.get(term)\n",
    "        for pEntry in entry.postingList:\n",
    "            if pEntry.maxTermFreq > maz:\n",
    "                maz = pEntry.maxTermFreq\n",
    "\n",
    "    for term in dictionary_uncomp.keys():\n",
    "        entry = dictionary_uncomp.get(term)\n",
    "        for pEntry in entry.postingList:\n",
    "            if pEntry.maxTermFreq == maz:            \n",
    "                return pEntry.docId,pEntry.maxTermFreq\n",
    "            \n",
    "def getDocLargestDocLen(dictionary_uncomp):\n",
    "    doc=0\n",
    "    for term in dictionary_uncomp.keys():\n",
    "        entry = dictionary_uncomp.get(term)\n",
    "        for pEntry in entry.postingList:\n",
    "            if pEntry.docLen > doc:\n",
    "                doc = pEntry.docLen\n",
    "\n",
    "    for term in dictionary_uncomp.keys():\n",
    "        entry = dictionary_uncomp.get(term)\n",
    "        for pEntry in entry.postingList:\n",
    "            if pEntry.docLen == doc:            \n",
    "                return pEntry.docId,pEntry.docLen\n",
    "            \n",
    "#Blocked compression using gamma coding\n",
    "def blockedCompression_gamma():#getGammaCode\n",
    "    k=8\n",
    "    tempK=0\n",
    "    dictString = \"\"\n",
    "    termFreqBlock = {}\n",
    "    docFreqBlock = {}\n",
    "    gammaEncodingList = []\n",
    "    tempIndexList = []\n",
    "    for f,term in enumerate(dictionary_uncomp_v1.keys()):\n",
    "        if tempK < k:\n",
    "            dictString += str(len(term)) + term\n",
    "            entry = dictionary_uncomp_v1.get(term)\n",
    "            prevId = 0\n",
    "            pEntry = PostingEntry(0,0,0,0)\n",
    "            for pEntry in entry.postingList:\n",
    "                docId = getGammaCode(pEntry.docId - prevId)\n",
    "                gammaEncodingList.append(docId)\n",
    "                prevId = pEntry.docId\n",
    "            termFreqBlock[tempK] = getGammaCode(entry.totTermFreq)\n",
    "            docFreqBlock[tempK] = getGammaCode(entry.docFreq)\n",
    "            tempK += 1\n",
    "             \n",
    "        if tempK == k or f == len(dictionary_uncomp_v1)-1:\n",
    "            tempK=0\n",
    "            tempIndexList.append(gammaEncodingList)\n",
    "            tempIndexList.append(termFreqBlock)\n",
    "            tempIndexList.append(docFreqBlock)\n",
    "            compressedIndexV1[dictString] = tempIndexList \n",
    "            dictString = \"\"\n",
    "            tempIndexList = []\n",
    "            gammaEncodingList = []\n",
    "            termFreqBlock = {}\n",
    "            docFreqBlock = {}\n",
    "                                \n",
    "    return compressedIndexV1\n",
    "\n",
    "#Blocked compression using delta coding\n",
    "def blockedCompression_delta(): #getDeltaCode\n",
    "    k=8\n",
    "    tempK=0\n",
    "    dictString = \"\"\n",
    "    termFreqBlock = {}\n",
    "    docFreqBlock = {}\n",
    "    gammaEncodingList = []\n",
    "    tempIndexList = []\n",
    "    for f,term in enumerate(dictionary_uncomp_v1.keys()):\n",
    "        if tempK < k:\n",
    "            dictString += str(len(term)) + term\n",
    "            entry = dictionary_uncomp_v1.get(term)\n",
    "            prevId = 0\n",
    "            pEntry = PostingEntry(0,0,0,0)\n",
    "            for pEntry in entry.postingList:\n",
    "                docId = getDeltaCode(pEntry.docId - prevId)\n",
    "                gammaEncodingList.append(docId)\n",
    "                prevId = pEntry.docId\n",
    "            termFreqBlock[tempK] = getDeltaCode(entry.totTermFreq)\n",
    "            docFreqBlock[tempK] = getDeltaCode(entry.docFreq)\n",
    "            tempK += 1\n",
    "             \n",
    "        if tempK == k or f == len(dictionary_uncomp_v1)-1:\n",
    "            tempK=0\n",
    "            tempIndexList.append(gammaEncodingList)\n",
    "            tempIndexList.append(termFreqBlock)\n",
    "            tempIndexList.append(docFreqBlock)\n",
    "            compressedIndexV1[dictString] = tempIndexList \n",
    "            dictString = \"\"\n",
    "            tempIndexList = []\n",
    "            gammaEncodingList = []\n",
    "            termFreqBlock = {}\n",
    "            docFreqBlock = {}\n",
    "                                \n",
    "    return compressedIndexV1\n",
    "\n",
    "#Blocked compression using unary coding\n",
    "def blockedCompression_unary(): #getUnaryValue\n",
    "    k=8\n",
    "    tempK=0\n",
    "    dictString = \"\"\n",
    "    termFreqBlock = {}\n",
    "    docFreqBlock = {}\n",
    "    gammaEncodingList = []\n",
    "    tempIndexList = []\n",
    "    for f,term in enumerate(dictionary_uncomp_v1.keys()):\n",
    "        if tempK < k:\n",
    "            dictString += str(len(term)) + term\n",
    "            entry = dictionary_uncomp_v1.get(term)\n",
    "            prevId = 0\n",
    "            pEntry = PostingEntry(0,0,0,0)\n",
    "            for pEntry in entry.postingList:\n",
    "                docId = getUnaryValue(pEntry.docId - prevId)\n",
    "                gammaEncodingList.append(docId)\n",
    "                prevId = pEntry.docId\n",
    "            termFreqBlock[tempK] = getUnaryValue(entry.totTermFreq)\n",
    "            docFreqBlock[tempK] = getUnaryValue(entry.docFreq)\n",
    "            tempK += 1\n",
    "             \n",
    "        if tempK == k or f == len(dictionary_uncomp_v1)-1:\n",
    "            tempK=0\n",
    "            tempIndexList.append(gammaEncodingList)\n",
    "            tempIndexList.append(termFreqBlock)\n",
    "            tempIndexList.append(docFreqBlock)\n",
    "            compressedIndexV1[dictString] = tempIndexList \n",
    "            dictString = \"\"\n",
    "            tempIndexList = []\n",
    "            gammaEncodingList = []\n",
    "            termFreqBlock = {}\n",
    "            docFreqBlock = {}\n",
    "                                \n",
    "    return compressedIndexV1\n",
    "\n",
    "\n",
    "def commonPrefix(m):\n",
    "    s1 = min(m)\n",
    "    s2 = max(m)\n",
    "    for i, c in enumerate(s1):\n",
    "        if c != s2[i]:\n",
    "            return s1[:i]\n",
    "    return s1\n",
    "\n",
    "#front encoding compression using gamma coding\n",
    "def frontCoding_gamma(): #getGammaCode\n",
    "    k=8\n",
    "    tempK=0\n",
    "    termFreqBlock = {}\n",
    "    deltaEncodingList = []\n",
    "    docFreqBlock = {}\n",
    "    termList= []\n",
    "    tempIndexList = []\n",
    "    prefix = \"\"\n",
    "    temp = \"\"\n",
    "    \n",
    "    for f,term in enumerate(sorted(dictionary_uncomp_v2.keys())):\n",
    "        if tempK < k:\n",
    "            termList.append(term)\n",
    "            tempK += 1\n",
    "        \n",
    "        if tempK == k or f == len(dictionary_uncomp_v2)-1 :    \n",
    "            prefix = commonPrefix(termList)\n",
    "            if prefix:\n",
    "                temp += \"[\"\n",
    "                for n,item in enumerate(termList):\n",
    "                    if item.startswith(prefix):\n",
    "                        if n == 0:\n",
    "                            temp += str(len(item)) + prefix + \"*\" + item[len(prefix):]\n",
    "                        if n > 0:\n",
    "                            temp += str(len(item[len(prefix):])) + \"|\" + item[len(prefix):]                 \n",
    "                    else:\n",
    "                        if n == 0:\n",
    "                            temp += str(len(item)) + prefix + \"*\" +  item[:]\n",
    "                        if n > 0:\n",
    "                            temp += str(len(item[:])) + \"|\" + item[:]\n",
    "                    \n",
    "                    entry = dictionary_uncomp_v2.get(item)\n",
    "                    prevId = 0\n",
    "                    pEntry = PostingEntry(0,0,0,0)\n",
    "                    \n",
    "                    for pEntry in entry.postingList:\n",
    "                        docId = getGammaCode(pEntry.docId - prevId)\n",
    "                        deltaEncodingList.append(docId)\n",
    "                        prevId = pEntry.docId\n",
    "                \n",
    "                    termFreqBlock[n] = getGammaCode(entry.totTermFreq)\n",
    "                    docFreqBlock[n] = getGammaCode(entry.docFreq)\n",
    "               \n",
    "                temp += \"]\"\n",
    "                tempIndexList.append(deltaEncodingList) \n",
    "                tempIndexList.append(termFreqBlock)\n",
    "                tempIndexList.append(docFreqBlock)\n",
    "                compressedIndexV2[temp] = tempIndexList \n",
    "                tempK=0\n",
    "                temp = \"\"\n",
    "                tempIndexList = []\n",
    "                termList = []\n",
    "                deltaEncodingList = []\n",
    "                termFreqBlock = {}\n",
    "                docFreqBlock = {}\n",
    "    return compressedIndexV2\n",
    "\n",
    "#front encoding compression using delta coding\n",
    "def frontCoding_delta():\n",
    "    k=8\n",
    "    tempK=0\n",
    "    termFreqBlock = {}\n",
    "    deltaEncodingList = []\n",
    "    docFreqBlock = {}\n",
    "    termList= []\n",
    "    tempIndexList = []\n",
    "    prefix = \"\"\n",
    "    temp = \"\"\n",
    "    \n",
    "    for f,term in enumerate(sorted(dictionary_uncomp_v2.keys())):\n",
    "        if tempK < k:\n",
    "            termList.append(term)\n",
    "            tempK += 1\n",
    "        \n",
    "        if tempK == k or f == len(dictionary_uncomp_v2)-1 :    \n",
    "            prefix = commonPrefix(termList)\n",
    "            if prefix:\n",
    "                temp += \"[\"\n",
    "                for n,item in enumerate(termList):\n",
    "                    if item.startswith(prefix):\n",
    "                        if n == 0:\n",
    "                            temp += str(len(item)) + prefix + \"*\" + item[len(prefix):]\n",
    "                        if n > 0:\n",
    "                            temp += str(len(item[len(prefix):])) + \"|\" + item[len(prefix):]                 \n",
    "                    else:\n",
    "                        if n == 0:\n",
    "                            temp += str(len(item)) + prefix + \"*\" +  item[:]\n",
    "                        if n > 0:\n",
    "                            temp += str(len(item[:])) + \"|\" + item[:]\n",
    "                    \n",
    "                    entry = dictionary_uncomp_v2.get(item)\n",
    "                    prevId = 0\n",
    "                    pEntry = PostingEntry(0,0,0,0)\n",
    "                    \n",
    "                    for pEntry in entry.postingList:\n",
    "                        docId = getGammaCode(pEntry.docId - prevId)\n",
    "                        deltaEncodingList.append(docId)\n",
    "                        prevId = pEntry.docId\n",
    "                \n",
    "                    termFreqBlock[n] = getDeltaCode(entry.totTermFreq)\n",
    "                    docFreqBlock[n] = getDeltaCode(entry.docFreq)\n",
    "               \n",
    "                temp += \"]\"\n",
    "                tempIndexList.append(deltaEncodingList) \n",
    "                tempIndexList.append(termFreqBlock)\n",
    "                tempIndexList.append(docFreqBlock)\n",
    "                compressedIndexV2[temp] = tempIndexList \n",
    "                tempK=0\n",
    "                temp = \"\"\n",
    "                tempIndexList = []\n",
    "                termList = []\n",
    "                deltaEncodingList = []\n",
    "                termFreqBlock = {}\n",
    "                docFreqBlock = {}\n",
    "    return compressedIndexV2\n",
    "\n",
    "#front encoding compression using unary coding\n",
    "def frontCoding_unary(): #getUnaryValue\n",
    "    k=8\n",
    "    tempK=0\n",
    "    termFreqBlock = {}\n",
    "    deltaEncodingList = []\n",
    "    docFreqBlock = {}\n",
    "    termList= []\n",
    "    tempIndexList = []\n",
    "    prefix = \"\"\n",
    "    temp = \"\"\n",
    "    \n",
    "    for f,term in enumerate(sorted(dictionary_uncomp_v2.keys())):\n",
    "        if tempK < k:\n",
    "            termList.append(term)\n",
    "            tempK += 1\n",
    "        \n",
    "        if tempK == k or f == len(dictionary_uncomp_v2)-1 :    \n",
    "            prefix = commonPrefix(termList)\n",
    "            if prefix:\n",
    "                temp += \"[\"\n",
    "                for n,item in enumerate(termList):\n",
    "                    if item.startswith(prefix):\n",
    "                        if n == 0:\n",
    "                            temp += str(len(item)) + prefix + \"*\" + item[len(prefix):]\n",
    "                        if n > 0:\n",
    "                            temp += str(len(item[len(prefix):])) + \"|\" + item[len(prefix):]                 \n",
    "                    else:\n",
    "                        if n == 0:\n",
    "                            temp += str(len(item)) + prefix + \"*\" +  item[:]\n",
    "                        if n > 0:\n",
    "                            temp += str(len(item[:])) + \"|\" + item[:]\n",
    "                    \n",
    "                    entry = dictionary_uncomp_v2.get(item)\n",
    "                    prevId = 0\n",
    "                    pEntry = PostingEntry(0,0,0,0)\n",
    "                    \n",
    "                    for pEntry in entry.postingList:\n",
    "                        docId = getUnaryValue(pEntry.docId - prevId)\n",
    "                        deltaEncodingList.append(docId)\n",
    "                        prevId = pEntry.docId\n",
    "                \n",
    "                    termFreqBlock[n] = getUnaryValue(entry.totTermFreq)\n",
    "                    docFreqBlock[n] = getUnaryValue(entry.docFreq)\n",
    "               \n",
    "                temp += \"]\"\n",
    "                tempIndexList.append(deltaEncodingList) \n",
    "                tempIndexList.append(termFreqBlock)\n",
    "                tempIndexList.append(docFreqBlock)\n",
    "                compressedIndexV2[temp] = tempIndexList \n",
    "                tempK=0\n",
    "                temp = \"\"\n",
    "                tempIndexList = []\n",
    "                termList = []\n",
    "                deltaEncodingList = []\n",
    "                termFreqBlock = {}\n",
    "                docFreqBlock = {}\n",
    "    return compressedIndexV2\n",
    "\n",
    "dirPath = \"C:\\\\Users\\\\Namrata\\\\Downloads\\\\cranfield\\*\"\n",
    "filesList = glob.glob(dirPath)\n",
    "\n",
    "#######################################################################################################\n",
    "compressedIndexV1 = defaultdict()\n",
    "compressedIndexV2 = defaultdict()\n",
    "dictionary_uncomp_v1 = dict()\n",
    "dictionary_uncomp_v2 = dict()\n",
    "dictWord = defaultdict(int)\n",
    "stemWord = defaultdict(int)\n",
    "docList = defaultdict(int)\n",
    "\n",
    "########################################################################################################\n",
    "start_time = time.time()\n",
    "Lemmatiztion()\n",
    "end_time = time.time()\n",
    "print(\"Elapsed time to build Index using lemmatization: version 1: \"+str(end_time - start_time)+\" seconds\") \n",
    "start = time.time()\n",
    "Stemming()\n",
    "end = time.time()\n",
    "print(\"Elapsed time to build Index using lemmatization : version 2: \"+str( end - start)+\" seconds\")\n",
    "print(\"\")\n",
    "#########################################################################################################\n",
    "with open('Index_Version1.uncompress', 'wb') as outfile:\n",
    "    pickle.dump(dictionary_uncomp_v1, outfile, pickle.HIGHEST_PROTOCOL)\n",
    "print(\"Size of the Index version 1 uncompressed (in bytes): \" + str(os.path.getsize(\"Index_Version1.uncompress\")))\n",
    "\n",
    "with open('Index_Version2.uncompress', 'wb') as outfile1:\n",
    "    pickle.dump(dictionary_uncomp_v2, outfile1, pickle.HIGHEST_PROTOCOL)\n",
    "print(\"Size of the Index version 2 uncompressed (in bytes): \" + str(os.path.getsize(\"Index_Version2.uncompress\")))\n",
    "print(\"\")\n",
    "\n",
    "########################################################################################################\n",
    "    \n",
    "blockedCompression_gamma()\n",
    "with open('Index_Version_blockedCompression_gamma.compress', 'wb') as outfile3:\n",
    "    pickle.dump(compressedIndexV1, outfile3, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "blockedCompression_delta()\n",
    "with open('Index_Version_blockedCompression_delta.compress', 'wb') as outfile4:\n",
    "    pickle.dump(compressedIndexV1, outfile4, pickle.HIGHEST_PROTOCOL)  \n",
    "    \n",
    "blockedCompression_unary()\n",
    "with open('Index_Version_blockedCompression_unary.compress', 'wb') as outfile2:\n",
    "    pickle.dump(compressedIndexV1, outfile2, pickle.HIGHEST_PROTOCOL) \n",
    "\n",
    "##########################################################################################################\n",
    "frontCoding_gamma()\n",
    "with open('Index_Version_frontCoding_gamma.compress', 'wb') as outfile5:\n",
    "   pickle.dump(compressedIndexV2, outfile5, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "frontCoding_delta()\n",
    "with open('Index_Version_frontCoding_delta.compress', 'wb') as outfile5:\n",
    "   pickle.dump(compressedIndexV2, outfile5, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "frontCoding_unary()\n",
    "with open('Index_Version_frontCoding_unary.compress', 'wb') as outfile5:\n",
    "   pickle.dump(compressedIndexV2, outfile5, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "print(\"Size of the Index compressed using blocked compression & unary coding (in bytes): \" + str(os.path.getsize(\"Index_Version_blockedCompression_unary.compress\")))\n",
    "print(\"Size of the Index compressed using blocked compression & gamma encoding (in bytes): \" + str(os.path.getsize(\"Index_Version_blockedCompression_gamma.compress\")))\n",
    "print(\"Size of the Index compressed using blocked compression & delta encoding (in bytes): \" + str(os.path.getsize(\"Index_Version_blockedCompression_delta.compress\")))\n",
    "\n",
    "print(\"Size of the Index compressed using front coding & unary codes (in bytes): \" + str(os.path.getsize(\"Index_Version_frontCoding_unary.compress\")))\n",
    "print(\"Size of the Index compressed using front coding & gamma codes (in bytes): \" + str(os.path.getsize(\"Index_Version_frontCoding_gamma.compress\")))\n",
    "print(\"Size of the Index compressed using front coding & delta codes (in bytes): \" + str(os.path.getsize(\"Index_Version_frontCoding_delta.compress\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
